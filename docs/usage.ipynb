{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebooks can sometime hard to work with. Some magic methods will be really handy when things don't seem to work out. The following cell reloads all changed modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Installation](#installation)\n",
    "2. [Motivation](#motivation)\n",
    "3. [Importing a dataset](#importing)\n",
    "4. [Attributes](#attributes)\n",
    "5. [Accessing Samples](#accessing)\n",
    "6. [Iteration over samples](#iteration)\n",
    "7. [Subset selection](#subset)\n",
    "8. [Saving/Loading a dataset](#saving)\n",
    "9. [Combining datasets](#merging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation<a name=\"installation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install MRdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from MRdataset import import_dataset\n",
    "# check if install worked\n",
    "# check version\n",
    "# upgrade command\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation<a name=\"motivation\"></a>\n",
    "Large scale neuroimaging datasets play an essential role in brain-behavior relationships. While neuroimaging studies have shown promising results, reproducibility can be affected by differences in acquisition parameters at the scanner level. The motivation behind creating MRdataset is to provide a unified interface to access image acquisition data, across various formats such as XNAT, BIDS, LONI etc.\n",
    "\n",
    "Having a unified interface to access image acquisition data is important because it allows users to easily and consistently access and manipulate the data, regardless of the specific format or source of the data. This can save time and reduce the potential for errors, as users do not need to worry about dealing with the nuances of different data formats or sources. In addition, a unified interface can make it easier to integrate image acquisition data with other systems and processes, allowing for more efficient and effective analysis and use of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing a dataset<a name=\"importing\"></a>\n",
    "To provide concrete examples, let's jump to an example right away. We will use an example dicom dataset to provide an example. Note that the outputs will be quite different based on your data. We will complete this tutorial using a dicom dataset. However, the libraries also support BIDS datasets. Example code for BIDS dataset would be discussed later in this tutorial\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset can be imported from disk, simply using the function `import_dataset`. Observe that it includes the functionality to add a `name` to the dataset, and also `style` is specified which can be one of either `dicom` or `bids`. As of now, we have an empty dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "DATA_ARCHIVE = '/home/sinhah/github/MRdataset/examples/example_dicom_data.zip'\n",
    "DATA_ROOT = Path('/tmp/')\n",
    "with zipfile.ZipFile(DATA_ARCHIVE, 'r') as zip_ref:\n",
    "    zip_ref.extractall(DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_dataset = import_dataset(data_root=DATA_ROOT/'example_dicom_data',\n",
    "                               style='dicom',\n",
    "                               name='dummy_study_experiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a dataset is empty, it means that there is no data stored in it. This can be a problem if the dataset is supposed to contain data that is needed for a particular analysis or task. In such cases, the absence of data can prevent the analysis or task from being performed, or it can lead to incorrect or incomplete results.\n",
    "\n",
    "We can check that `dicom_dataset` is empty, by printing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dicom_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often beneficial to have a separate method for reading data because it allows the user to explicitly control when the data is read. This can be useful in cases where the data is very large or complex, as it allows the user to manage the amount of data that is being processed at any given time. Additionally, having a separate method for reading data can make the overall design of the code more modular and flexible, as it allows the user to easily swap out different data sources or change the way that the data is read without having to modify the rest of the code.\n",
    "\n",
    "After creating the `dicom_dataset` object, the user must call `.walk()` method to read the data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_dataset.walk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `print()` method to see the contents of a dataset can be beneficial because it allows the user to quickly and easily view the data, without having to write additional code to extract and display the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dicom_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we print `dicom_dataset` again, it prints concise information about the dataset, i.e. the number of modalities inside dataset (12). It also mentions the type of dataset, i.e. DicomDataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `print_tree()` can be especially useful when working with large or complex datasets, as it can be difficult to manually inspect the data and identify any patterns or issues. It can help the user to verify that the data has been correctly read and processed, and to diagnose any problems that may have occurred during the reading or processing of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_dataset.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will dicuss the complete description of this method, `print_tree()` later in this tutorial. Let's complete our discussion on importing a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noted that when we used `.walk()`, there are log messages informing that many files have been skipped. The method skips any file which it identifies as a localizer. In general, these are not required, but you still want to include them in your object, a flag `include_phantom` can be used to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '/home/sinhah/github/MRdataset/examples/example_dicom_data/'\n",
    "dicom_dataset_w_phantom = import_dataset(data_root=DATA_ROOT,\n",
    "                               style='dicom',\n",
    "                               name='dummy_study_experiment',\n",
    "                               include_phantom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we used earlier,  if we invoke the method `.walk()`, we don't see the output messages that any file has been skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_dataset_w_phantom.walk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we see some warning messages, saying that some localizer files have some issues in their parameters. This is expected as localizers are not valid MRI volumes. Localizer are short scans the allows the scanner to setup correctly. Note that these checks/warnings are still under active development and one may observe these messages even if files from your project has perfectly valid MRI scan volumes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going further, lets dig deeper what are the elements present in our dataset. It is essential to describe the elements of a dataset because it helps to provide context and information about the data that is contained in the dataset. This can be useful for other users or researchers who are working with the MRdataset, as it allows them to understand the structure and how it should be interpreted. In addition, describing the elements of a dataset can help to ensure that the data structure is being used correctly and consistently, and it can also facilitate the integration of the dataset with other data sources or systems. \n",
    "\n",
    "The library has hierarchichal structure as displayed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](mrdataset-structure.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above figure shows a simple schematic to depict the structure of MRdataset object. \n",
    "\n",
    "Different MRI modalities, such as T1-weighted, T2-weighted, and diffusion-weighted imaging, can provide different types of information about the structure and composition of tissues in the body. Additionally, MRI scans are often performed on multiple subjects, such as healthy individuals and patients with a specific condition, in order to compare and contrast the differences in their anatomy and physiology. This can help researchers to better understand the underlying mechanisms of a particular condition or disease, and to develop more effective treatments.\n",
    "\n",
    "Similarly, the MRdataset object is a hierarchical data structure that is made up of different elements of a neuroimaging experiment, such as modalities, subjects, sessions and runs. Each element is represented as a node in a tree, and the edges connect the nodes to show hierarchical relationship between data elements. \n",
    "\n",
    "So, the **dataset** is at the top of the tree, and the various modalities beneath it, like T1-weighted, T2-weighted and diffusion-weighted are branching out of the dataset. The term **modality** refers to the specific technique that is used to acquire the imaging data. Each modality contains several subjects, which are part of the experiments. Observe that different modalities may typically have common subjects, in order to compare and contrast the differences in their brain anatomy and function. \n",
    "\n",
    "Each **subject** may have one or more sessions for a modality. The term **session** refers to a specific imaging session that is performed on a given subject. Typically, there would be multiple sessions in order to obtain multiple sets of data for a given subject. Often, a subject return to MR Research center several time during a span of 1-2 years, which helps in tracking longitudnal changes in the brain.\n",
    "\n",
    "Finally, **run** refers to a specific set if imaging data that is acquired during a given session. Often, a single session will involve multiple runs to obtain a comprehensive acquisition. For example, an fMRI experiment involves multiple runs, each of which acquires information about particular brain region or might even have a different behavioral task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe this hierarchical structure in our dataset `dicom_dataset` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{dicom_dataset.name} dataset contains following modalities:\")\n",
    "for modality in dicom_dataset.modalities:\n",
    "    print('\\t',modality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can browse through each one of modalities, to see that they contain several subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{dicom_dataset.name} dataset contains following modalities:\")\n",
    "for modality in dicom_dataset.modalities:\n",
    "    print('\\t', modality)\n",
    "    for subject in modality.subjects:\n",
    "        print('\\t\\t', subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `print_tree()` directly rather than manually iterating through a for-loop. This can be especially useful when working with large or complex datasets, as it can be difficult to manually inspect the data and identify any patterns or issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_dataset.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading a dataset<a name=\"saving\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving and loading a dataset is important because it allows you to store and retrieve your data for later use. This is especially useful when you have a large dataset that takes a long time to process or generate, or when you want to share your dataset with others.\n",
    "\n",
    "By saving your dataset, you can avoid having to recreate it each time you want to use it, which can save you a significant amount of time and resources. Additionally, storing your dataset in a structured and organized way can make it easier to analyze and manipulate later on.\n",
    "\n",
    "Overall, the ability to save and load a dataset is a valuable tool that can help you work more efficiently and effectively with your data.\n",
    "\n",
    "We use `save_mr_dataset` and `load_mr_dataset` to save and load MRdataset objects, respectively. Let's see an example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MRdataset import save_mr_dataset, load_mr_dataset\n",
    "save_mr_dataset(filepath='/home/sinhah/github/MRdataset/examples/example_dicom.mrds.pkl', \n",
    "                mrds_obj=dicom_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_dicom_dataset = load_mr_dataset(filepath='/home/sinhah/github/MRdataset/examples/example_dicom.mrds.pkl',\n",
    "                                   style='dicom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Samples<a name=\"accessing\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "filepath=Path('/home/sinhah/github/MRdataset/examples/example_dicom.mrds.pkl')\n",
    "filepath.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MRdataset.base import find_dataset_using_style\n",
    "dataset_class = find_dataset_using_style('dicom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Iteration over Samples<a name=\"iteration\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset Selection<a name=\"subset\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Merging Datasets<a name=\"merging\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
